# オーディオストリーミング

## オーディオフォーマット

| パラメータ | クライアント → サーバー | サーバー → クライアント |
|-----------|----------------|-----------------|
| サンプルレート | 入力デバイスに依存 | 48,000 Hz |
| ビット深度 | 16-bit signed | 16-bit signed |
| エンコーディング | PCM little-endian | PCM little-endian |
| チャンネル | モノラル | モノラル |
| トランスポート | JSON 内の Base64 | JSON 内の Base64 |

## 入力パイプライン

```
Microphone ──> Browser AudioContext ──> PCM chunks ──> Base64 ──> WebSocket
                                                                    │
                                                               Main Server
                                                                    │
                                                    OmniRealtimeClient.send_audio()
                                                                    │
                                                              LLM Provider
```

サーバーは内部でサンプルレート変換を処理します。一般的なサンプルレート（44.1kHz、48kHz など）の入力オーディオが受け入れられます。

## 出力パイプライン

```
LLM Provider ──> on_audio_delta ──> 24kHz PCM
                                        │
                                   soxr resampler
                                        │
                                   48kHz PCM ──> Base64 ──> WebSocket ──> Browser
```

`soxr` ライブラリは、LLM のネイティブ 24kHz からブラウザの 48kHz 再生レートへの高品質なサンプルレート変換を提供します。

## 割り込み

キャラクターがオーディオを出力中にユーザーが話し始めた場合：

1. LLM プロバイダーが `on_interrupt` を発火する
2. TTS リクエストとレスポンスキューがフラッシュされる
3. 保留中のオーディオフレームが破棄される
4. キャラクターが即座に発話を停止する
5. システムが新しいユーザー入力の処理を開始する

これにより、音声会話での自然なターンテイキングが可能になります。

## 音声アクティビティ検出（VAD）

N.E.K.O. はデフォルトで**サーバーサイド VAD** を使用します。LLM プロバイダー（例：Qwen Omni）が音声境界を自動的に検出します。これは以下を意味します：

- クライアントサイドの VAD 設定は不要
- サーバーがユーザーの発話終了を判断
- 発話内の自然な間（ポーズ）がインテリジェントに処理される

## ネイティブ画像入力

音声セッション中、システムは画面データのキャプチャと送信も可能です：

- 最小間隔：キャプチャ間 **1.5 秒**
- アイドルレート乗数：**5x**（音声アクティビティがない場合、画像の送信頻度が低下）
- マルチモーダル理解のためにオーディオと一緒に画像が送信される

## ノイズリダクション

`pyrnnoise` を使用したオプションのノイズリダクション：

- 最初のオーディオ入力時に遅延ロード
- LLM プロバイダーにオーディオを送信する前に適用
- 入力オーディオが既にクリーンな場合は無効化可能
